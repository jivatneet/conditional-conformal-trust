{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f188aa",
   "metadata": {},
   "source": [
    "# Conditional Conformal Prediction with Custom Function Class [WIP]\n",
    "\n",
    "This notebook allows you to perform conditional conformal prediction using any custom function class you define. The function class should take model outputs as input and return features for conditional conformal prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e94187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Navigate to the project root directory and add necessary paths\n",
    "current_dir = os.getcwd()\n",
    "project_root = current_dir\n",
    "\n",
    "while not (os.path.exists(os.path.join(project_root, 'experiments')) and \n",
    "           os.path.exists(os.path.join(project_root, 'conditionalconformal'))):\n",
    "    parent = os.path.dirname(project_root)\n",
    "    if parent == project_root:  \n",
    "        break\n",
    "    project_root = parent\n",
    "\n",
    "# Add the necessary paths to the system path\n",
    "experiments_path = os.path.join(project_root, 'experiments')\n",
    "if experiments_path not in sys.path:\n",
    "    sys.path.append(experiments_path)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "from utils.conformal import compute_conformity_score, compute_conformity_score_softmax, compute_conformity_score_aps, compute_conformity_score_raps, compute_sets_split, compute_sets_cond\n",
    "from utils.model import get_image_classifier, split_test\n",
    "from utils.data import get_image_dataset\n",
    "from utils.evaluation import aggregate_results_over_seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366da92",
   "metadata": {},
   "source": [
    "### Define Your Custom Function Class\n",
    "\n",
    "Create your custom function class that will generate features for conditional conformal prediction. The class should have a `compute_features` method that takes model outputs and returns features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFunctionClass:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize your custom function class\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def compute_features(self, logits, features=None):\n",
    "        \"\"\"Compute features for conditional conformal prediction\n",
    "        \n",
    "        Args:\n",
    "            logits: Model output logits of shape (n_samples, n_classes)\n",
    "            features: Optional model features of shape (n_samples, feature_dim)\n",
    "            \n",
    "        Returns:\n",
    "            phi: Features for conditional conformal prediction of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        # Example: Use maximum softmax probability as a feature\n",
    "        probs = softmax(logits, axis=1)\n",
    "        max_probs = np.max(probs, axis=1, keepdims=True)\n",
    "        return max_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e18b64",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d05fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and parameters\n",
    "DATA_DIR = '/path/to/data'\n",
    "CACHE_DIR = '/path/to/pretrained_model'\n",
    "FEATURES_DIR = '/path/to/precomputed/features'\n",
    "OUTPUT_DIR = './outputs'\n",
    "\n",
    "# Model and dataset parameters\n",
    "dataset_name = 'imagenet'  # Choose from: imagenet, places, imagenet_lt, places_lt\n",
    "model_name = 'resnet50'    # Choose appropriate model for your dataset\n",
    "batch_size = 64\n",
    "\n",
    "# Conformal prediction parameters\n",
    "alpha = 0.1               # Significance level\n",
    "score_fn = 'aps'         # Conformity score function: softmax, aps, or raps\n",
    "scores_randomize = False  # Whether to randomize scores\n",
    "temp_scaling = True      # Whether to use temperature scaling\n",
    "degree = 5               # Polynomial feature degree\n",
    "seed = 1                 # Random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab05b8",
   "metadata": {},
   "source": [
    "### Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load model\n",
    "model, preprocess = get_image_classifier(model_name, device=device)\n",
    "\n",
    "# Load dataset and compute/load features\n",
    "if dataset_name in [\"imagenet\", \"places\"]:\n",
    "    train_dataset, test_dataset = get_image_dataset(dataset_name, preprocess=preprocess)\n",
    "    test_features, test_logits, test_labels = model.run_and_cache_outputs(test_dataset, batch_size, FEATURES_DIR)\n",
    "    test_labels, test_features, test_logits, _, calib_labels, calib_features, calib_logits, _ = split_test(\n",
    "        test_labels, test_features, test_logits, split=0.5, seed=seed\n",
    "    )\n",
    "else:\n",
    "    train_dataset, val_dataset, test_dataset = get_image_dataset(dataset_name, preprocess=preprocess)\n",
    "    calib_features, calib_logits, calib_labels = model.run_and_cache_outputs(val_dataset, batch_size, FEATURES_DIR)\n",
    "    test_features, test_logits, test_labels = model.run_and_cache_outputs(test_dataset, batch_size, FEATURES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fa040",
   "metadata": {},
   "source": [
    "### Compute Features using Custom Function Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your custom function class\n",
    "custom_function = CustomFunctionClass()\n",
    "\n",
    "# Compute features for calibration and test sets\n",
    "calib_phi = custom_function.compute_features(calib_logits, calib_features)\n",
    "test_phi = custom_function.compute_features(test_logits, test_features)\n",
    "\n",
    "# Apply polynomial features if degree > 1\n",
    "if degree > 1:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    calib_phi = poly.fit_transform(calib_phi)\n",
    "    test_phi = poly.transform(test_phi)\n",
    "\n",
    "print('Feature shapes:', calib_phi.shape, test_phi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60307b",
   "metadata": {},
   "source": [
    "### Compute conformity scores and prediction sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute base conformity scores\n",
    "calib_scores, test_scores = compute_conformity_score(calib_logits, test_logits, calib_labels, test_labels, temp_scaling=temp_scaling)\n",
    "\n",
    "# Compute method-specific conformity scores\n",
    "if score_fn == \"softmax\":\n",
    "    calib_scores, test_scores, test_scores_all = compute_conformity_score_softmax(\n",
    "        calib_logits, test_logits, calib_labels, test_labels, temp_scaling=temp_scaling\n",
    "    )\n",
    "elif score_fn == \"aps\":\n",
    "    calib_scores, test_scores, test_scores_all = compute_conformity_score_aps(\n",
    "        calib_logits, test_logits, calib_labels, test_labels, rand=scores_randomize, temp_scaling=temp_scaling\n",
    "    )\n",
    "elif score_fn == \"raps\":\n",
    "    calib_scores, test_scores, test_scores_all = compute_conformity_score_raps(\n",
    "        calib_logits, test_logits, calib_labels, test_labels, rand=scores_randomize, temp_scaling=temp_scaling\n",
    "    )\n",
    "\n",
    "# Compute prediction sets for split conformal\n",
    "coverages_split, prediction_sets_split, set_sizes_split = compute_sets_split(\n",
    "    calib_scores, test_scores, test_scores_all, alpha\n",
    ")\n",
    "\n",
    "# Compute prediction sets for conditional conformal\n",
    "coverages_cond, prediction_sets_cond, set_sizes_cond = compute_sets_cond(\n",
    "    calib_phi, calib_scores, test_phi, test_scores, test_scores_all, alpha, rand=scores_randomize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4482e5",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "results_dir = os.path.join(OUTPUT_DIR, f\"{dataset_name}_{model_name}\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Create filename based on parameters\n",
    "res_fname = f\"alpha_{alpha}_score_fn_{score_fn}_scores_randomize_{scores_randomize}_temp_scale_{temp_scaling}_custom_fn_degree_{degree}_seed_{seed}\"\n",
    "\n",
    "# Save results\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_calib_phi.npy\"), calib_phi)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_test_phi.npy\"), test_phi)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_coverages_split.npy\"), coverages_split)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_prediction_sets_split.npy\"), prediction_sets_split)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_set_sizes_split.npy\"), set_sizes_split)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_coverages_cond.npy\"), coverages_cond)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_prediction_sets_cond.npy\"), prediction_sets_cond)\n",
    "np.save(os.path.join(results_dir, f\"{res_fname}_set_sizes_cond.npy\"), set_sizes_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d3761",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation parameters\n",
    "datasets = {\n",
    "    'ImageNet': 'imagenet',\n",
    "    'ImageNet-LT': 'imagenet_lt',\n",
    "    'Places365': 'places',\n",
    "    'Places365-LT': 'places_lt',\n",
    "}\n",
    "\n",
    "score_fns = {\n",
    "    'APS': 'aps',\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'ImageNet': 'resnet50',\n",
    "    'ImageNet-LT': 'resnext50_imagenet_lt',\n",
    "    'Places365': 'resnet152_places',\n",
    "    'Places365-LT': 'resnet152_places_lt',\n",
    "}\n",
    "\n",
    "methods = {\n",
    "    'split': '$\\\\mathsf{split}$',\n",
    "    'conditional': '$\\\\mathsf{conditional}$',\n",
    "}\n",
    "\n",
    "# Aggregate results\n",
    "for dataset, dataset_name in datasets.items():\n",
    "    for score_fn, score_fn_name in score_fns.items():\n",
    "        results_dir = os.path.join(OUTPUT_DIR, f\"{dataset_name}_{models[dataset]}\")\n",
    "        res_fname = f\"alpha_{alpha}_score_fn_{score_fn_name}_scores_randomize_{scores_randomize}_temp_scale_{temp_scaling}_custom_fn\"\n",
    "        df = aggregate_results_over_seeds(dataset_name, models[dataset], FEATURES_DIR, results_dir, res_fname, None, methods.keys(), score_fn_name, degree)\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49170ec5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conformal-trust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
